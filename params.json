{
  "name": "Ncaa 2016",
  "tagline": "NCAA tournament pipeline",
  "body": "\r\n# ncaa_2016 kaggle competition\r\n\r\nTeam Members: \r\n\r\n- [Stefan Wojcik](http://spot.colorado.edu/~stwo0664/index.html)\r\n- [Thomas Cook](www.thomasrcook.com)\r\n\r\n\r\n\r\n![](bracket.png)\r\n\r\n\r\n\r\n# NCAA tournament pipeline\r\nThe workhorse for this year's predictions was a caret ensembe model fed through a pipeline that assembeled data. \r\n\r\n![](ActivityDiagram1.png)\r\n\r\n# General principles\r\n\r\n* scripts that manipulate data should be placed in data_building\r\n\t* builder_script.R should be last script specified in config (see below)\r\n\t* should not directly load files or call directories -- pipeline.R will load requested files based on config file. \r\n\t* preceding building scripts should yield or pass object called `tourney.file`\r\n\r\n* scripts that run models should be placed in modeling_scripts\r\n\t* should not directly load or list paths to  outside data or files. These will be provided by the preceeding data_building scripts and files specified in config\r\n\t* scripts should be written to expect three objects already loaded into memory: `test_data`, `training_data`, and `validation_data`\r\n\t* modeling_scripts should exit with an object called `model` in memory that can be used with predict\r\n\t\t* pipeline will eventually take this `model` and produce validation data (i'll add this in tomorrow)\r\n* config file:\r\n\t* can be R (longer and annoying to edit -- see config.R.example)\r\n\t* can also be yaml (easier to write)\r\n\t* pipeline.R will automatically write the config.yaml from config.R\r\n\t* details on what goes in config file below.\r\n\r\n\r\nRun with `source(\"pipeline.R\")` from R.\r\n\r\n# To use: \r\n\r\n\r\ncreate a config.yaml file that specifies the following: \r\n\r\n```{yaml}\r\n\r\n\r\n\r\n\r\npath_to_NCAA: ~/Google Drive/NCAA/\r\nrepository_location: /s/Programming/NCAA_2016\r\n\r\nfirst.training.season: 2005\r\nlast.training.season: 2009\r\n\r\nfirst.validation.season: 2010\r\nlast.validation.season: 2015\r\ntraining_split:.3\r\n\r\ndata_building_files:\r\n- data_building/other_scripts.R \r\n- data_building/builder_script.R\r\n# you should probably always include this file last in this list. \r\n\r\nmodel_files:\r\n- modeling_scripts/pre_analysis.R # a script to run\r\n- modeling_scripts/analysis03142015.R\r\n\r\n\r\ndata_to_load:\r\n# These are specified as dataset_name: dataset_location -- relative to the ncaa folder\r\n  kaggle.submission.file: 2016_competition/data_2016_specific/kaggle_dataset/SampleSubmission.rds\r\n  season.file: 2016_competition/data_2016_specific/kaggle_dataset/RegularSeasonDetailedResults.csv\r\n  tourney.file: 2016_competition/data_2016_specific/kaggle_dataset/TourneyCompactResults.csv\r\n\r\nfeatures_to_add:\r\n  Seed: 2016_competition/data_2016_specific/kaggle_dataset/TourneySeeds.rds\r\n  RPI: General_Data/some_file.csv\r\n  # Note, the name of the element (e.g. RPI) is used as the name in this list.\r\n  # The name of the element here should correspond to the name of the name of\r\n  # the column for the feature in the datafile (e.g. some_file.csv should have a\r\n  # column named RPI).\r\noutput_file: submission.csv\r\n# this is where the submission csv will be generated relative to repo root. \r\n\r\n```\r\n\r\nAlternatively, you can specifiy this in a file called config.R and the pipeline\r\nwill generate the corresponding yaml file for you. This is a more finicky way of\r\ndoing this though and the file must be structured very similarly to\r\nconfig.R.example.\r\n\r\n## Description of parameters\r\n\r\n### path_to_NCAA\r\n\r\nthis is required. it is the path to the NCAA folder on your local machine. \r\n\r\n### repository_location\r\n\r\nthis is required. it is the path to this repo on your local machine.\r\n\r\n### features_to_add\r\n\r\nThese are specified as feature_name: feature_location -- relative to the ncaa\r\nfolder. The feature dataset should have 3 columns: one for\r\n\r\n### data_to_load\r\n\r\nthese are the names and locations of the datasets to load in. they are specified\r\nrelative to the root of the NCAA folder. At least one of these should be named\r\n`tourney.file'. if using the builder_script, this dataset will form the base\r\ndataset into which features are merged. The tourney.file in the example above is\r\nthe location of the compact tourney results file supplied by kaggle.\r\n\r\n\r\n### last.training.season and first.training.season\r\n\r\nthese is used by `getTourneyData()` in the builder_script to properly subset\r\ndata for a specified set of  seasons. This should not overlap with the\r\nvalidation.season parameters.\r\n\r\n### last.validation.season and first.validation.season\r\n\r\nthese is used by `test_train_validate_split()` in the builder_script to properly\r\nsubset data for a specified set of  seasons for validation. This should be the\r\nrange of seasons over which we want to predict outcomes and submit. In the final\r\nround of the competition, this will be 2016 for both values\r\n\r\n### training_split\r\n\r\nThis is the proportion of the training data that you want the builder_script to\r\nhold out for cross validation of the trained model. if your modeling script uses\r\nsomethign like carat where you can do more advanced cross validation, you can\r\nset `training_split: 0` in yaml (or put `training_split=0` in the `data_recipe`\r\nlist in `config.R`) This will prevent `builder_script.R` from splitting the\r\ntraining data (`builder_script.R` will still return `test_data`, but it will be\r\n`NULL`)\r\n\r\n### data_building_files:\r\n\r\nthese are files specified relative to the repo root. They are files you want to\r\nrun to manipulate data prior to model estimation. You should probably keep the\r\nbuilder_script as the last element of this list  as this script will properly\r\ntransform the tourney data and load features in the `features_to_add` list. The\r\nbuilder_script file will expect a dataframe called tourney.file to be in memory\r\nand it will return three objects at its conclusion: `test_data`, `training_data`\r\nand `validation_data`.\r\n\r\n\r\n### model_files: \r\n\r\nthese are the model building files that are run to generate model estimates.\r\nthese scripts should expect an object called tourneydata and return a model\r\nobject with a standard predict method.\r\n\r\n\r\n### output_file\r\nThis is where the submission csv will be generated relative to repo root. \r\n\r\n## short-term changes\r\n\r\nI will also add a final step that takes the model object returned from\r\nmodel_files and use it to produce a kaggle- formatted submission file.\r\n\r\n\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}